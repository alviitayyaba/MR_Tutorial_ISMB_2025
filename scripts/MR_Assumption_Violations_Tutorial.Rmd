---
title: "Mendelian Randomization: Demonstrating Assumption Violations with Toy Data"
output: html_document
---

This tutorial demonstrates how Mendelian Randomization (MR) results can be biased when its core assumptions are violated. Each section introduces a potential violation and how to detect or mitigate it using simulated data. 
## Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(TwoSampleMR)
library(ggplot2)
library(dplyr)
library(data.table)
```

---

## Part 1: Simulate Toy GWAS Data

We simulate 100 SNPs with p-values reflecting a realistic GWAS distribution. Effect sizes are drawn from a normal distribution; standard errors are constant for simplicity.

```{r part1-simulate}
# Simulate GWAS data for exposure

set.seed(123)
n_snps <- 100
N <- 10000  # sample size

# Simulate EAF for SNPs
eaf <- runif(n_snps, 0.05, 0.5) 

# Simulate beta.exposure 
beta_exposure <- c(
  rnorm(n_snps, mean = 0, sd = 0.05)
)

# Calculate SEs based on MAF and N
se_exposure <- 1 / sqrt(2 * N * eaf * (1 - eaf))

# Compute exposure Z and p-values
z_exposure <- beta_exposure / se_exposure
pval_exposure <- 2 * pnorm(-abs(z_exposure))

exposure_gwas <- data.frame(
  SNP = paste0("rs", 1:n_snps),
  beta.exposure = beta_exposure,
  se.exposure = se_exposure,
  pval.exposure = pval_exposure,
  effect_allele.exposure = sample(c("A", "G"), n_snps, replace = TRUE),
  other_allele.exposure = sample(c("T", "C"), n_snps, replace = TRUE),
  eaf.exposure = eaf,
  id.exposure = "exposure",
  exposure = "TraitX",
  CHR = sample(1:22, n_snps, replace = TRUE),
  BP = sample(1:1e6, n_snps)
)

# Simulate outcome beta with true causal effect
true_causal_effect <- 0.4
beta_outcome <- true_causal_effect * beta_exposure + rnorm(n_snps, 0, 0.02)
se_outcome <- se_exposure  # matched for simplicity
z_outcome <- beta_outcome / se_outcome
pval_outcome <- 2 * pnorm(-abs(z_outcome))

outcome_gwas <- data.frame(
  SNP = exposure_gwas$SNP,
  beta.outcome = beta_outcome,
  se.outcome = se_outcome,
  pval.outcome = pval_outcome,
  effect_allele.outcome = exposure_gwas$effect_allele.exposure,
  other_allele.outcome = exposure_gwas$other_allele.exposure,
  eaf.outcome = exposure_gwas$eaf.exposure,
  id.outcome = "outcome",
  outcome = "TraitY",
  CHR = exposure_gwas$CHR,
  BP = exposure_gwas$BP
)



exposure_gwas <- exposure_gwas %>%
  arrange(CHR, BP) %>%
  mutate(logp = -log10(pval.exposure),
         pos = BP + (CHR - 1) * 1e6)
ggplot(exposure_gwas, aes(x = pos, y = logp, color = as.factor(CHR))) +
  geom_point(alpha = 0.7) +
  geom_hline(yintercept = -log10(5e-8), linetype = "dashed", color = "red") +
  geom_hline(yintercept = -log10(1e-5), linetype = "dotted", color = "blue") +
  labs(x = "Genomic position (concatenated chromosomes)",
       y = "-log10(p-value.exposure)",
       color = "Chromosome",
       title = "Simulated GWAS Manhattan Plot") +
  theme_bw()
```

##Exercise 1: Look at the Manhattan plot. How many SNPs are genome-wide significant?

```{r Exercise 1}
sum(exposure_gwas$pval < 5e-8)
```

---

## Part 2: LD Clumping and Independence

```r
# Simulated LD clumping: Keep one SNP per chromosome

# Note: This is a simplified approach to approximate LD clumping. In real GWAS datasets, linkage disequilibrium (LD) is based on correlation between SNPs due to their physical proximity on the genome. Clumping typically removes SNPs that are in high LD (e.g., r^2 > 0.01) within a given window (e.g., 10,000 kb). By keeping only one SNP per chromosome here, we ensure independence in a naive way, which is sufficient for toy examples but does not reflect the finer structure of LD in real data.
```
```{r part2-LD-clumping}
exposure_gwas_clumped <- exposure_gwas %>% group_by(CHR) %>% slice_min(pval.exposure, n = 1) %>% ungroup()
combined <- exposure_gwas %>%
  mutate(type = "All SNPs") %>%
  bind_rows(exposure_gwas_clumped %>% mutate(type = "Clumped SNPs"))

ggplot(combined, aes(x = factor(CHR), y = -log10(pval.exposure), color = type)) +
  geom_jitter(width = 0.2, alpha = 0.7) +
  labs(x = "Chromosome", y = "-log10(p-value.exposure)", color = "Dataset",
       title = "SNP p-values before and after simplified LD clumping") +
  theme_bw()
```

##Exercise 2: Why do we keep only one SNP per chromosome here? What assumptions are we making?

We assume that SNPs on different chromosomes are independent (no LD across chromosomes). Keeping one SNP per chromosome mimics removing correlated SNPs in LD within chromosomes, a simplified version of clumping.

---

## Part 3: Harmonization and Palindromic SNPs

```{r part4-mr-no-pleiotropy}
# Simulate outcome data
# Introduce palindromic SNPs
palindromic <- sample(1:nrow(outcome_gwas), 3)
outcome_gwas$effect_allele.outcome[palindromic] <- "A"
outcome_gwas$other_allele.outcome[palindromic] <- "T"

# Harmonize
harmonized <- harmonise_data(exposure_gwas_clumped, outcome_gwas)
mr_results <- mr(harmonized, method_list = c("mr_ivw", "mr_egger_regression"))
pleio_test <- mr_pleiotropy_test(harmonized)
print(mr_results)
print(pleio_test)
mr_scatter_plot(mr_results, harmonized )
```

##Exercise 3: Identify palindromic SNPs. How are they handled during harmonization?

---

## Part 4: Invalid Instruments & Weak Instrument Bias

```{r part5-Weak Instrument Bias}
# Introduce weak instruments
# Note: SNPs with high p-values for exposure association (e.g., > 0.05) are considered weak instruments.
# Weak instruments explain very little variance in the exposure and can lead to biased or imprecise MR estimates,
# particularly in small sample sizes or when using methods assuming strong instruments.
# Simulate all weak instruments
exposure_gwas_weak <- exposure_gwas_clumped
exposure_gwas_weak$beta.exposure <- rnorm(nrow(exposure_gwas_weak), 0, 0.08)
exposure_gwas_weak$se.exposure <- rep(0.05, nrow(exposure_gwas_weak))
exposure_gwas_weak$pval.exposure <- 2 * pnorm(-abs(exposure_gwas_weak$beta.exposure / exposure_gwas_weak$se.exposure))

# Harmonize
harm_weak <- harmonise_data(exposure_gwas_weak, outcome_gwas)
harm_weak$F_stat <- (harm_weak$beta.exposure / harm_weak$se.exposure)^2
summary(harm_weak$F_stat)  # Should be <10 if weak
# MR with weak instruments
mr_results_weak <- mr(harm_weak, method_list = c("mr_ivw", "mr_egger_regression"))
print(mr_results_weak)
mrobust <- mr_heterogeneity(harm_weak)
print(mrobust)
mr_scatter_plot(mr_results_weak, harm_weak)
```

##Exercise 4: What is the effect of weak SNPs on the MR estimate?
Answer:
Weak instruments have little association with the exposure, biasing MR estimates towards null and increasing uncertainty, reducing reliability and power.

---

## Part 5: Detecting Pleiotropy

```{r part6-Detecting Pleiotropy}
# Introduce pleiotropy by altering outcome effects
# Horizontal pleiotropy occurs when a genetic variant affects the outcome through pathways other than the exposure,
# violating the exclusion restriction assumption of Mendelian Randomization. One way to simulate this is by
# artificially increasing the effect sizes of some SNPs on the outcome, independent of their effects on the exposure.

set.seed(456)


harm_pleio <- harmonise_data(exposure_gwas_clumped, outcome_gwas)
n_snps <- nrow(harm_pleio)
# Assign 4 SNPs as valid instruments and 18 as pleiotropic
pleiotropic_snps <- harm_pleio$SNP[1:18]
valid_snps <- harm_pleio$SNP[19:22]

# Simulate exposure effects (beta.exposure)
harm_pleio$beta.exposure[harm_pleio$SNP %in% valid_snps] <- rnorm(4, mean = 0.1, sd = 0.05)   # valid SNPs: stronger effects
harm_pleio$beta.exposure[harm_pleio$SNP %in% pleiotropic_snps] <- rnorm(18, mean = 0.05, sd = 0.005) # pleiotropic: weak effect

# Simulate outcome effects (beta.outcome)
causal_effect <- 0.3
pleiotropy_effect <- rnorm(18, mean = 0.08, sd = 0.02)

harm_pleio$beta.outcome[harm_pleio$SNP %in% valid_snps] <- causal_effect * harm_pleio$beta.exposure[harm_pleio$SNP %in% valid_snps] + rnorm(4, 0.001, 0.005)
harm_pleio$beta.outcome[harm_pleio$SNP %in% pleiotropic_snps] <- pleiotropy_effect + rnorm(18, 0.1, 0.05)  # outcome driven by pleiotropy

# run MR
mr_results_pleio <- mr(harm_pleio, method_list = c("mr_ivw", "mr_egger_regression"))
pleio_test_pleio <- mr_pleiotropy_test(harm_pleio)

print(mr_results_pleio)
print(pleio_test_pleio)
p <- mr_scatter_plot(mr_results_pleio, harm_pleio)
p1 <- p[[1]]
p1$data$pleiotropic <- ifelse(p1$data$SNP %in% pleiotropic_snps, "Pleiotropic", "Non-pleiotropic")

p_final <- p1 +
  ggnewscale::new_scale_color() +
  geom_point(aes(x = beta.exposure, y = beta.outcome, color = pleiotropic), data = p1$data, size = 2) +
  scale_color_manual(values = c("Pleiotropic" = "red", "Non-pleiotropic" = "blue")) 
print(p_final)
```

##Exercise 5: Use `mr_pleiotropy_test` and interpret the Egger intercept. What does a non-zero intercept indicate in terms of pleiotropy?
Answer: A significant MR-Egger intercept suggests directional horizontal pleiotropy, meaning some SNPs affect the outcome via pathways other than the exposure, violating MR assumptions.


---

## Part 6: Addressing Pleiotropy via Confounder Filtering
```{r part7-Addressing Pleiotropy via conf}
# Simulate confounder (BMI) associations
bmi_gwas <- exposure_gwas_clumped
bmi_gwas$beta <- exposure_gwas_clumped$beta.exposure + rnorm(nrow(bmi_gwas), 0, 0.1)
bmi_gwas$pval <- 10^(-runif(nrow(bmi_gwas), 1, 10))

# Remove overlapping SNPs
# Filtering out SNPs associated with a confounder like BMI helps reduce pleiotropic bias because these SNPs may influence both the exposure and the outcome through the confounder. Removing them increases the likelihood that the remaining instruments affect the outcome only via the exposure, thereby upholding the exclusion restriction assumption of MR.
shared_snps <- intersect(bmi_gwas$SNP[bmi_gwas$pval < 5e-8], exposure_gwas_clumped$SNP)
exposure_filtered <- exposure_gwas_clumped[!exposure_gwas_clumped$SNP %in% shared_snps, ]

harm_conf <- harmonise_data(exposure_filtered, outcome_gwas)
pleio_test <- mr_pleiotropy_test(harm_conf)
mr_clean <- mr(harm_conf, , method_list = c("mr_ivw","mr_egger_regression"))
print(pleio_test)
mr_scatter_plot(mr_clean , harm_conf)
```

##Exercise 6: Does removing BMI-associated SNPs reduce pleiotropy?
Answer:
SNPs linked to confounders may violate the exclusion restriction assumption by influencing the outcome through alternative pathways, biasing MR estimates. Filtering these improves validity.
---

This walkthrough highlights how various assumption violations can bias MR estimates and how to correct for them. It is designed to stimulate critical thinking during hands-on learning.
